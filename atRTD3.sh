


####generate all the correspondence between sample names and file names


find . -name "*subreads.bam" > readfile

for i in `cat readfile` 
do 
FName=${i%/*};
FName1=${i##*/};
FName2=${FName1%%.*};

cd ${FName}/

rm -r output

rm -v !(*.subreads.bam)

cd /mnt/shared/scratch/rz41242/2017Isoseq/sam

done


##sparate clontech and Telo libaries
less readfile | grep Clonetech > readfile1

###Telo libaries
less readfile | grep -v Clonetech > readfile2
 
#!/bin/bash
#$ -cwd
#$ -j yes
#$ -pe mpi 28
#####$ -t 1-25
#$ -t 1-2


conda activate isoseq3

#INFILE=`awk "NR==$SGE_TASK_ID" readfile2`
INFILE=`awk "NR==$SGE_TASK_ID" readfile1`

FName=${INFILE%/*};
FName1=${INFILE##*/};
FName2=${FName1%%.*};

cd ${FName}/

###step1: Circular Consensus Sequence calling ccs 4.0.0 (commit v4.0.0)
ccs --min-rq 0.9 -j 28 ${FName2}.subreads.bam ${FName2}.ccs.bam 

###step 2 Primer removal and demultiplexing lima 1.10.0 (commit v1.10.0)
##If there are more than two sequences in your primer.fasta file or better said more than one pair of 5' and 3' primers, please use lima with --peek-guess to remove spurious false positive signal.
lima ${FName2}.ccs.bam teloprimer.fasta ${FName2}.fl.bam --isoseq --peek-guess
lima ${FName2}.ccs.bam clontechPrimer.fasta ${FName2}.fl.bam --isoseq --peek-guess

###step 3: refine: 1)Trimming of poly(A) tails; 2) Rapid concatmer identification and removal isoseq3 3.2.2 (commit v3.2.2)

isoseq3 refine ${FName2}.fl.F0_5p--R0_3p.bam teloprimer.fasta ${FName2}.flnc.bam
isoseq3 refine ${FName2}.fl.F0_5p--R0_3p.bam clontechPrimer.fasta ${FName2}.flnc.bam --require-polya

####convert bam files to fasta files
samtools fasta ${FName2}.flnc.bam > ${FName2}.flnc.fasta


####minimap2 2.17-r941
###output sam format
###--splice-flank=no no assumptions of the nucleotide after GT and AG
###--secondary=no no secondary alignments were made; made little difference to the mapped locations (m54053_190724_162631, from 314688 to 314729)


minimap2 -ax splice:hq -uf -G 6000 ArabidopsisGenome.fa ${FName2}.flnc.fasta > ${FName2}_isoseq_flnc.fasta.sam 2> ${FName2}_isoseq_flnc.fasta.sam.log

##sort the sam file: samtools 1.9 Using htslib 1.9

samtools sort -o ${FName2}_isoseq_flnc.fasta.sorted.sam ${FName2}_isoseq_flnc.fasta.sam
##filtered out reads with no mapping -F 4
samtools view -h -F 4 ${FName2}_isoseq_flnc.fasta.sorted.sam > ${FName2}_isoseq_flnc.fasta.sorted.filtered.sam

###Run TAMA collapse version 2019.09.13
###5' and 3' threshold 10nt
###-m Exon/Splice junction threshold


python tama_collapse.py -s ${FName2}_isoseq_flnc.fasta.sorted.filtered.sam -f ArabidopsisGenome.fa -p ${FName2}_isoseq_flnc_collasped -d merge_dup -x  no_cap -m 0 -a 0 -z 0 -sj sj_priority -lde 30 -sjt 30


####sep 30, 2019

###########use files generated by CCS, classify and TAMA
##/mnt/shared/scratch/rz41242/2017Isoseq/sam

awk 'BEGIN{print "fileName\t#ZMW\t#CCS"}'> ReadStat

for i in `cat readfile` 
do 

FName=${i%/*};
FName1=${i##*/};
FName2=${FName1%%.*};

####statistics up to CCS
cat ${FName}/ccs_report.txt | awk -v fileN="$FName2" '{if(NR==1){zwm=$5}; if(NR==2){zwm1=$6};}END{print fileN"\t"zwm"\t"zwm1>> "ReadStat"}'

done

####FLNC
awk 'BEGIN{print "#FL"}'> FLStat

for i in `cat readfile` 
do 

FName=${i%/*};
FName1=${i##*/};
FName2=${FName1%%.*};

cat ${FName}/${FName2}.fl.lima.summary | awk '{ if(NR==2){ print $7 >> "FLStat"}}'

done

#####mapped reads, collapsed transcripts/genes

awk 'BEGIN{print "#mappedLocations"}'> mappedLocationStat
awk 'BEGIN{print "#UniquemappedFLNCs"}'> UniquemappedFLNCs
awk 'BEGIN{print "#transcripts"}'> TranscriptStat
awk 'BEGIN{print "#genes"}'> GeneStat

for i in `cat readfile` 
do 

FName=${i%/*};
FName1=${i##*/};
FName2=${FName1%%.*};

samtools view -c -F 4 ${FName}/${FName2}_isoseq_flnc.fasta.sorted.filtered.sam >> mappedLocationStat

cat ${FName}/${FName2}_isoseq_flnc_collasped_read.txt | cut -f1 | sed '1d' | sort | uniq | wc -l >> UniquemappedFLNCs

cat ${FName}/${FName2}_isoseq_flnc_collasped_trans_report.txt | cut -f1 | sed '1d'| wc -l >> TranscriptStat

cat ${FName}/${FName2}_isoseq_flnc_collasped_trans_report.txt | cut -f1 | sed '1d'| tr "." "\t" | cut -f1 | sort | uniq | wc -l >> GeneStat

done
######
paste ReadStat FLStat UniquemappedFLNCs mappedLocationStat  TranscriptStat GeneStat > ReadStat1.txt



###run TAMA merge
###5' and 3' threshold 0 nt

source activate python_2.7

python tama_merge.py -f filelist1.txt -p merged -m 0 -a 0 -z 0 -d merge_dup 

source deactivate

######################################################
####splice junction analysis
###############################################

##########generate SJs from final transcripts from TAMA merge for PWM analysis

cat merged.bed | awk -F"\t" '{split($4, a, ";"); split($11, b, ","); split($12, c, ",");d=""; for (i = 1; i < $10; i++){print a[2]"\t"$1"_"c[i]+$7+b[i]+1"_"c[i+1]+$7"_"$6}}'  > SJ_16Oct2019

less SJ_16Oct2019 | cut -f2 | sort | uniq > SJ_16Oct2019_nonRedundant

cat SJ_16Oct2019_nonRedundant | awk '{split($1,a, "_"); print a[1]"\t"a[2]"\t"a[3]"\tJunction"NR"\t1000\t"a[4]}'> SJ_16Oct_PWM


####generate all the SJ error information
#!/bin/bash
#$ -cwd
#$ -j yes
#$ -t 1-27


INFILE=`awk "NR==$SGE_TASK_ID" readfile`

FName=${INFILE%/*};
FName1=${INFILE##*/};
FName2=${FName1%%.*};

cd ${FName}

###extract the error profiles for all the SJs of each transcript
###output: read number/the ith SJ/the error profile
cat ${FName2}_isoseq_flnc_collasped_local_density_error.txt | awk '{split($12, a, ";");if(NR>1){for (i = 1; i < $7; i++){print $1"\t"i"\t"a[i]}; delete a}}' > ${FName2}_read_SJ_error_30_30

####associate the reads to the transcript id from TAMA collapse
cat ${FName2}_read_SJ_error_30_30 | awk -v  prefix=${FName2} 'BEGIN{file=prefix"_isoseq_flnc_collasped_trans_read.bed"; while(getline<file){split($4, a, ";");b[a[2]]=a[1]}}{print b[$1]"\t"$1"\t"$2"\t"$3}' > ${FName2}_transcript_read_SJ_error_30_30


cat ${FName2}_isoseq_flnc_collasped.bed | awk -F"\t" '{split($4, a, ";"); split($11, b, ","); split($12, c, ",");d=""; for (i = 1; i < $10; i++){print a[2]"\t"i"\t"$1"_"c[i]+$7+b[i]+1"_"c[i+1]+$7"_"$6}}'  > SJ_lde


####associate the SJ coordinates to the file
cat ${FName2}_transcript_read_SJ_error_30_30 | awk  -v  prefix=${FName2} 'BEGIN{while(getline<"SJ_lde"){b[$1][$2]=$3}}{print prefix"_"$1"\t"$2"\t"$3"\t"$4"\t"b[$1][$3]}' > ${FName2}_transcript_read_SJ_Coord_error_30_30

rm SJ_lde ${FName2}_transcript_read_SJ_error_30_30 ${FName2}_read_SJ_error_30_30

done


############################################
###filtering for SJs: 
#1) canonical SJs only ; 
#2)finding the SJs with zero mismatches with 10nt around the SJs;

########################################



###collate all the SJ error informations 

cat m*_transcript_read_SJ_Coord_error_30_30 > all_transcript_read_SJ_Coord_error_30_30


####Dec 18th, 2019
####get the error profiles around SJs
#### Sort the SJs and count the number of matches for each SJ



####NF=5 removes some reads that were thrown out by TAMA collapse with no transcripts associate to
cat all_transcript_read_SJ_Coord_error_30_30 | awk 'NF==5{print $5"\t"$4}'| sort | awk '{print $1"\t"$2"\t"gsub("_", "", $2)}'> IsoSJ_ErrorProfile

####sort the + and -e
export LC_ALL=C
cat IsoSJ_ErrorProfile | sort -k1 > IsoSJ_ErrorProfile_Sorted

#####Take the best match for each splice juction/only retain one read with highest number of matches
cat IsoSJ_ErrorProfile_Sorted | awk 'BEGIN{while(getline<"IsoSJ_ErrorProfile_Sorted"){if((!a[$1])||($3>a[$1])){a[$1]=$3}}}{if(NR==1||SJ!=$1){SJ=$1;flag=1};if($3==a[$1]&&flag==1){print $1"\t"$2"\t"$3;flag=0}}'> IsoSJ_ErrorProfile_BestRead

###splice junction analysis
####17 Dec, 2019

###############atRTD2#####################################

perl /home/rz41242/software/gtf2gff/gtf2gff3.pl --cfg gtf2gff3.cfg  AtRTD2_19April2016.gtf > AtRTD2_19April2016.gff

/home/rz41242/software/GenomeTools/bin/gt gff3 -sort yes -retainids yes -tidy yes -checkids yes -addintrons yes AtRTD2_19April2016.gff | grep -v "#" > /mnt/shared/scratch/rz41242/2017Isoseq/sam/SplicedJunctions/AtRTD2_19April2016_intron.gff


cat AtRTD2_19April2016_intron.gff | awk -F"\t" '$3=="intron"{split($9, a, "=");d=$1"_"$4"_"$5"_"$7; print a[2]"\t"d}'| sort | uniq > SJ_RTD2

##unique sjs 151,944
less SJ_RTD2 | cut -f2 | sort | uniq | wc -l


##########generate SJs from Iso-seq TAMA merge
##/mnt/shared/scratch/rz41242/2017Isoseq/sam/LDE_30_30_HD

cat merged.bed | awk -F"\t" '{split($4, a, ";"); split($11, b, ","); split($12, c, ",");d=""; for (i = 1; i < $10; i++){print a[2]"\t"$1"_"c[i]+$7+b[i]+1"_"c[i+1]+$7"_"$6}}'  > SJ_30_30


###compare the overlaps of the SJs
cat SJ_30_30 | cut -f2 | sort | uniq > SJ_30_30_sorted
cat SJ_RTD2 | cut -f2 | sort | uniq > SJ_RTD2_sorted


###shared SJs: 124,328, SJs unique to RTD2: 27,616 and SJs unique to Iso-seq: 110,992
comm -12 SJ_30_30_sorted SJ_RTD2_sorted | wc -l

comm -23 SJ_30_30_sorted SJ_RTD2_sorted > Isoseq_SJ_unique
comm -12 SJ_30_30_sorted SJ_RTD2_sorted > Isoseq_SJ_shared

######error profiles arounds the unique SJs in Iso-seq data (110,992)

cat IsoSJ_ErrorProfile_BestRead | awk 'BEGIN{while(getline<"Isoseq_SJ_unique"){a[$1]="True"}}{if(a[$1]=="True"){print $1"\t"$2"\t"$3}}'> Unique_IsoSJ_ErrorProfile_BestRead

###########get the error statistics
#####1)calculate the number of errors for j bases nearest to the SJS
#####2)if the error is zero, then the SJs is retained
####It gives the number of SJs left if we filter based on zero errors on the N bases nearest to SJs. 
rm FilteredSJNumber_SJUnique_LDE_30_30
for j in {0..30}
do
echo $j
less Unique_IsoSJ_ErrorProfile_BestRead | awk -v i=$j '{split($2, a, ">");c=substr(a[1],length(a[1])-i+1 ,i);b= substr(a[2],1,i); if(gsub("_", "", c)==i&&gsub("_", "", b)==i){print $1}}'| sort | uniq | wc -l >> FilteredSJNumber_SJUnique_LDE_30_30
done
###########get the error statistics

less Unique_IsoSJ_ErrorProfile_BestRead | awk 'BEGIN{for (i = 1; i < 27; i++){L[i]=0; R[i]=0}}{split($2, a, ">"); for (i = 1; i <=length(a[1]); i++){if(substr(a[1], i, 1)!~"_"){L[length(a[1])-i+1]++}};for (i = 1; i <= length(a[2]); i++){if(substr(a[2], i, 1)!~"_"){R[i]++}}}END{for(i = 1; i < length(L)+1; i++){print "L"i"\t"L[i]};for (i = 1; i < length(R)+1; i++){print "R"i"\t"R[i]}}'> SJUnique_LDE_30_30_positionError

######error profiles arounds the shared SJs in Iso-seq data (110,992)

cat IsoSJ_ErrorProfile_BestRead | awk 'BEGIN{while(getline<"Isoseq_SJ_shared"){a[$1]="True"}}{if(a[$1]=="True"){print $1"\t"$2"\t"$3}}'> Shared_IsoSJ_ErrorProfile_BestRead

###########get the error statistics
#####1)calculate the number of errors for j bases nearest to the SJS
#####2)if the error is zero, then the SJs is retained
####It gives the number of SJs left if we filter based on zero errors on the N bases nearest to SJs. 
rm FilteredSJNumber_Overlap
for j in {0..30}
do
echo $j
less Shared_IsoSJ_ErrorProfile_BestRead | awk -v i=$j '{split($2, a, ">");c=substr(a[1],length(a[1])-i+1 ,i);b= substr(a[2],1,i); if(gsub("_", "", c)==i&&gsub("_", "", b)==i){print $1}}'| sort | uniq | wc -l >> FilteredSJNumber_Overlap
done

######calculate the number of errors for each base near to the SJ
less Shared_IsoSJ_ErrorProfile_BestRead | awk 'BEGIN{for (i = 1; i < 27; i++){L[i]=0; R[i]=0}}{split($2, a, ">"); for (i = 1; i <=length(a[1]); i++){if(substr(a[1], i, 1)!~"_"){L[length(a[1])-i+1]++}};for (i = 1; i <= length(a[2]); i++){if(substr(a[2], i, 1)!~"_"){R[i]++}}}END{for(i = 1; i < length(L)+1; i++){print "L"i"\t"L[i]};for (i = 1; i < length(R)+1; i++){print "R"i"\t"R[i]}}'> SJOverlap_positionError

#############PWM analysis


####combine PWM info with SJ info for 235,036 SJs with info, SJs from mitochondria and chloroplast are removed.
cat SJ_16Oct_PWM | awk 'BEGIN{while(getline<"Scores_SJ_16Oct_PWM.tab"){a[$1]=$0}}a[$4]{print $1"_"$2"_"$3"_"$6"\t"$0"\t"a[$4]}'> SJ_16Oct_PWM_Scores

####get PWM scores for shared SJS (124,315)
cat SJ_16Oct_PWM_Scores | awk 'BEGIN{while(getline<"Isoseq_SJ_shared"){a[$1]="True"}}{if(a[$1]=="True"){print}}'> SJ_16Oct_PWM_Scores_shared

####get PWM scores for unique SJS (110,721)
cat SJ_16Oct_PWM_Scores | awk 'BEGIN{while(getline<"Isoseq_SJ_unique"){a[$1]="True"}}{if(a[$1]=="True"){print}}'> SJ_16Oct_PWM_Scores_unique

###


#####Carry out Filtering

###get the intron motifs
cat all_transcript_read_SJ_Coord_error_30_30 | awk 'BEGIN{while(getline<"/home/rz41242/Projects/2017IsoSeq/genome/ArabidopsisGenome.fa"){if(/>/){chr=substr($1, 5, 1)}else{a[chr]=$0;}}}{split($5, b, "_"); ch=substr(b[1], 4, 1);print ch"\t"$1"\t"substr(a[ch], b[2], 2) substr(a[ch], b[3]-1, 2)}'> IntronMotif_all_transcript_read_SJ_Coord_error_30_30

####attach the intron motif information
cut -f3 IntronMotif_all_transcript_read_SJ_Coord_error_30_30 | paste all_transcript_read_SJ_Coord_error_30_30 - >  all_transcript_read_SJ_Coord_motif_error_30_30

#### 1)finding the SJs with zero mismatches with 10nt around the SJs; 2) Remove transcripts with unsupported SJs. That allows to borrow the information from other reads with no mis-matches

###1)canonical SJs only  ; 2)finding the SJs with zero mismatches with 10nt around the SJs;  
cat all_transcript_read_SJ_Coord_motif_error_30_30 | awk '{if($6=="GTAG"||$6=="GCAG"||$6=="ATAC"||$6=="CTAC"||$6=="CTGC"||$6=="GTAT"){print}}'| awk '{split($4, a, ">");c=substr(a[1],length(a[1])-9 ,10);b= substr(a[2],1,10); if(gsub("_", "", c)==10&&gsub("_", "", b)==10){print $5}}'| sort | uniq > SJ_supported_All1

###get the sequences near the SJs for template switching analysis (edit distance/hamming distance)
cat SJ_supported_All1 | awk 'BEGIN{while(getline<"ArabidopsisGenome.fa"){if(/>/){chr=substr($1, 5, 1)}else{a[chr]=$0;}}}{split($1, b, "_"); ch=substr(b[1], 4, 1);print ch"\t"$1"\t"substr(a[ch], b[2]-8, 8)"\t"substr(a[ch], b[2], 8)"\t"substr(a[ch], b[3]-7, 8)"\t"substr(a[ch], b[3]+1, 8)}'> Template_SJ_supported_All1



##########generate SJs from final transcripts from TAMA merge

cat merged.bed | awk -F"\t" '{split($4, a, ";"); split($11, b, ","); split($12, c, ",");d=""; for (i = 1; i < $10; i++){print a[2]"\t"$1"_"c[i]+$7+b[i]+1"_"c[i+1]+$7"_"$6}}'  > SJ_30_30

###get the transcripts with unsupported SJs (177,579 transcripts removed)

less SJ_30_30 | awk -F"\t" 'BEGIN{while(getline<"SJ_supported_All1"){a[$1]=1}}{if(a[$2]!=1){print $1}}' | sort | uniq >  transcripts_unsupported1

## remove transcripts with unsupported SJs in bed file

cat merged.bed | awk -F"\t" 'BEGIN{while(getline<"transcripts_unsupported1"){a[$1]=1}}{split($4, b, ";"); if(a[b[2]]!=1){print}}' >  merged_LDE_30_30_filtered1.bed



######################################################
####TSS and TES analysis
###############################################

############################################
###filtering for 3' and 5' positions: 
#1) ployA.txt
#2) distribution of 5' and 3' locations



for i in `cat readfile`
 do
 FName=${i%/*};
 FName1=${i##*/};
 FName2=${FName1%%.*};
 echo $FName2
 #######get the CCS reads whose ends mapped to polyA region and get the location of those ends
 cat ${FName}/${FName2}_isoseq_flnc_collasped_trans_read.bed  | awk -v file=${FName}/${FName2}_isoseq_flnc_collasped_polya.txt 'BEGIN{while(getline<file){a[$1]=1}}{split($4, b, ";");if(a[b[2]]==1){print $1"\t"$2"\t"$3"\t"$6}}'>> temp
 ##########get the transcript start and end locations supported by CCS reads
 cat ${FName}/${FName2}_isoseq_flnc_collasped_trans_read.bed  | cut -f1,2,3,6 >> temp1
done

less temp | sort | uniq | sort -k1,1 -k2,2n > LDE_30_30_HD/FinalComparison/TES_polyA

###should not done unique

less temp1 | sort | uniq -c | awk '{print $2"\t"$3"\t"$4"\t"$5"\t"$1}'| sort -k1,1 -k2,2n > LDE_30_30_HD/FinalComparison/TSS_TES




###############for transcriptionals starting sites, only use the teloprime libraries
rm temp2

for i in `cat readfile2`
 do
 FName=${i%/*};
 FName1=${i##*/};
 FName2=${FName1%%.*};
 echo $FName2
 ##########get the transcript start and end locations supported by CCS reads
 cat ${FName}/${FName2}_isoseq_flnc_collasped_trans_read.bed  | cut -f1,2,3,6 >> temp2
done

less temp2 | sort | uniq -c | awk '{print $2"\t"$3"\t"$4"\t"$5"\t"$1}'|  sort -k1,1 -k2,2n > LDE_30_30_HD/FinalComparison/TSS_telo




############transcript end sites################


less ../../temp1 | awk '{if($4=="+"){print $1"\t"$3"\t"$4}else{print $1"\t"$2"\t"$4}}'| sort | uniq -c | awk '{print $2"\t"$3"\t"$4"\t"$1}'| sort -k1,1 -k2,2n > TES_histogram

ln=`cat TES_histogram | wc -l`
cat TES_histogram | cut -f4 | sort | uniq -c | awk -v n=$ln '{print $2"\t"$1"\t"$1/n}'| sort -n > TES_histogram_Stats

###May 5th, 2020
####for high abundance transcripts, the each TSS and TES have a probability assigned by binomial distribution


###input: merged50.bed TSS_histogram
cat ../merged.bed | awk '{split($4, a, ";");if($6=="+"){b[$1][$3][$6]=a[1];print $1"\t"$3"\t"$6"\t"b[$1][$3][$6]}else{b[$1][$2][$6]=a[1];print $1"\t"$2"\t"$6"\t"b[$1][$2][$6]}}'| sort | uniq > TES_gene

cat TES_histogram | awk 'BEGIN{while(getline<"TES_gene"){b[$1][$2][$3]=$4}}{print b[$1][$2][$3]"\t"$0}' | sort >  TES_histogram_gene

###input: merged.bed TSS_histogram

conda activate gmp

R
getwd() 		#get working directory

rm(list=ls()) 	#remove all variables in the current session
#install.packages('gmp')
library(gmp)
#set working directory 
###read in the transcript coordinates; re-use the code from the TSS analysis
TSS_histogram_gene<-read.table("TES_histogram_gene", header=F, as.is=T, sep="\t", comment.char="", strip.white=TRUE)
###get the SD for smaller coordinate and the bigger coordinate of each gene 
TSS_gene_sum<-aggregate(TSS_histogram_gene[,5], by=list(TSS_histogram_gene[,1]), FUN=sum)
TSS_gene_average<-aggregate(TSS_histogram_gene[,5], by=list(TSS_histogram_gene[,1]), FUN=mean)

###pvalue for each site
pv <- rep(1, nrow(TSS_histogram_gene))
###number of locations (TSS) of each gene
loc <- rep(0, nrow(TSS_histogram_gene))
###total number of reads in a gene
Sr <- rep(0, nrow(TSS_histogram_gene))
###average number of reads per site in a gene
Ar<- rep(0, nrow(TSS_histogram_gene))

####when assigning n reads to m locations, for each location, the probability of having k reads in this postions is factorial(n)/(factorial(n-k)*factorial(k))*(1/m)^k*((m-1)/m)^(n-k)
###choose k out of n reads, the probability of the these k reads assigning to the same location is (1/m)^k, the probability that the rest of the reads (n-k) being assigned to other locations is ((m-1)/m)^(n-k).

for (i in 1:nrow(TSS_histogram_gene))
#for (i in 1:151)
{
print(i)
##total number of TSS sites
N_sites<-length(which(TSS_histogram_gene[ ,1]==TSS_histogram_gene[i,1]));
###number of reads at the current location
Reads1<-TSS_histogram_gene[i,5];
####number of reads at all TSS locations for this gene
Reads2<-TSS_gene_sum[which(TSS_gene_sum[ ,1]==TSS_histogram_gene[i,1]),2]
##when assigning n reads to m locations, for each location, the probability of having k reads in this postions is factorial(n)/(factorial(n-k)*factorial(k))*(1/m)^k*((m-1)/m)^(n-k)
#pv[i]<-factorial(Reads2)/(factorial(Reads2-Reads1)*factorial(Reads1))*(1/N_sites)^Reads1*((N_sites-1)/N_sites)^(Reads2-Reads1)

pv[i] <-as.numeric(factorialZ(Reads2)/(factorialZ(Reads2-Reads1)*factorialZ(Reads1))*(1/N_sites)^Reads1*((N_sites-1)/N_sites)^(Reads2-Reads1))

loc[i]<-N_sites
Sr[i]<-Reads2
Ar[i]<-Reads2/N_sites
}

TSS_prob<-cbind(TSS_histogram_gene, pv, loc, Sr, Ar)
names(TSS_prob)<- c("Gene","Chr", "TES_site","strand", "reads", "pv", "#loc", "totalReads", "AverageReads")



write.table(TSS_prob, file="TES_prob.txt", row.names = F,col.names = T, quote = FALSE, sep ="\t")

save.image(file = "TES.RData", version = NULL, ascii = FALSE,compress = FALSE, safe = TRUE)

load('TES.RData')



#####shell script
#####adding the reads over the window of 11nt; filter the TES with polyA tails (712,200)
cat TES_prob.txt | awk 'BEGIN{while(getline<"TES_histogram_Filtered_10"){a[$1][$2][$3]=$4}}{if(NR==1){print $0"\tReads_Window10"}else{if(a[$2][$3][$4]) print $0"\t"a[$2][$3][$4]}}'> TES_prob1.txt

####back in R 
#####load in the new TSS file
TES_prob1<-read.table("TES_prob1.txt", header=T, as.is=T, sep="\t", comment.char="", strip.white=TRUE)

TES_prob2<-TES_prob1[order(TES_prob1$Chr, TES_prob1$TES_site, decreasing=F),]

######TES that are enriched using probability of 0.05 
Ind<-which(TES_prob2$pv<0.05&TES_prob2$reads>TES_prob2$AverageReads)
##&TSS_prob1$Reads_Window10>=2

####number of genes with enriched TES 
length(unique(TES_prob2[Ind, 1]))

####get the number of total TES sites for the genes with enriched TES sites (669,642, which is 94.02% of total TSS sites)
length(which((TES_prob2[,1]) %in% unique(TES_prob2[Ind, 1])))

######get all the TSS sites from Genes with no enriched TSS (42,558 TSS from 13,440 genes)
GeneNotEnrichedInd<-which(!(TES_prob2[,1] %in% unique(TES_prob2[Ind, 1])))
###get the genes that are not enriched (13,440 genes)
GeneNotEnriched<-unique(TES_prob2[GeneNotEnrichedInd,1])


######get statistics on the total number of reads
###total read quantiles for genes with enriched TES
quantile(unique(TES_prob2[Ind, c(1,8)])[,2], probs = c(0:10)/10)

###total read quantiles for genes with no enriched TES
quantile(unique(TES_prob2[GeneNotEnrichedInd, c(1,8)])[,2], probs = c(0:10)/10)

###total TES sites quantiles for genes with enriched TES
quantile(unique(TES_prob2[Ind, c(1,7)])[,2], probs = c(0:10)/10)

###total TES sites quantiles for genes with no enriched TES
quantile(unique(TES_prob2[GeneNotEnrichedInd, c(1,7)])[,2], probs = c(0:10)/10)
## 0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100%
## 1    1    1    1    1    2    3    4    7   13  172

###enriched TES sites quantiles for genes with enriched TES after filtering
quantile(as.data.frame(table(TES_prob2[Ind,1]))$Freq, probs = c(0:10)/10)


#####stratification

####enriched TES
TES_enriched<-TES_prob2[Ind, ]
write.table(TES_enriched, file="TES_enriched.txt", row.names = F,col.names = T, quote = FALSE, sep ="\t")
####non enriched TES
write.table(TES_prob2[-Ind, ], file="TES_NonEnriched.txt", row.names = F,col.names = T, quote = FALSE, sep ="\t")

####

Ind_w <- rep(0, nrow(TES_prob2))
for (i in Ind)
{
print(i);
Ind_w[i]<-1
j<-i-1
while(abs(TES_prob2$TES_site[i]-TES_prob2$TES_site[j])<=50&TES_prob2$Chr[i]==TES_prob2$Chr[j]&TES_prob2$strand[i]==TES_prob2$strand[i]&j>1)
{
#print(j)
Ind_w[j]<-1
j<-j-1
}

j<-i+1;
while(abs(TES_prob2$TES_site[i]-TES_prob2$TES_site[j])<=50&TES_prob2$Chr[i]==TES_prob2$Chr[j]&TES_prob2$strand[i]==TES_prob2$strand[i]&j<nrow(TES_prob2))
{Ind_w[j]<-1
j<-j+1}
}

####number of TESs within the 100nt of the enriched TES (364,026) 
length(which(Ind_w==1))
write.table(TES_prob2[which(Ind_w==1),], file="TES_enriched_window.txt", row.names = F,col.names = T, quote = FALSE, sep ="\t")



####non-enriched TES with more than 2 reads (21,664 TSS sites)
Ind2<-which(!(TES_prob2[,1] %in% unique(TES_prob2[Ind, 1]))&TES_prob2[,10]>=2)
TES_Nenriched<-TES_prob2[Ind2, ]

####number of genes with no enriched TES after read filtering
length(unique(TES_prob2[Ind2, 1]))

###total TES sites quantiles for genes with enriched TES after filtering
quantile(as.data.frame(table(TES_prob2[Ind2,1]))$Freq, probs = c(0:10)/10)

write.table(TES_Nenriched, file="TES_Nenriched.txt", row.names = F,col.names = T, quote = FALSE, sep ="\t")



q()


######concatenate TES from enriched window and non enriched TES with reads>2 (585,151 TSSs)

cat TES_enriched_window.txt TES_Nenriched.txt > TES_highConf



#####compare the significant REGLs to TES peaks from DRS
###June 15th, 2020
### 


###TES peak from DRS 
dos2unix TES_DRS.txt
####add in peakID
cat TES_DRS.txt | awk 'NR>1{print $0"\tP"NR-1}'> TES_DRS1.txt

cat TES_DRS1.txt | sed 's/fwd/+/g' | sed 's/rev/-/g' | sed 's/chr/Chr/g' | awk '{print $2"\t"$4"\t"$4"\t"$3"\t100\t"$7"_"$1}' > DRS_Peak.bed


###TES sites
cat TES_enriched.txt | awk 'NR>1{print $2"\t"$3"\t"$3"\t"$1"\t100""\t"$4}' > TES_enriched.bed
cat TES_enriched.txt | awk 'NR>1{print $2"\t"$3-5"\t"$3+5"\t"$1"\t100""\t"$4}' > TES_enriched5.bed
cat TES_enriched.txt | awk 'NR>1{print $2"\t"$3-10"\t"$3+10"\t"$1"\t100""\t"$4}' > TES_enriched10.bed
cat TES_enriched.txt | awk 'NR>1{print $2"\t"$3-20"\t"$3+20"\t"$1"\t100""\t"$4}' > TES_enriched20.bed
cat TES_enriched.txt | awk 'NR>1{print $2"\t"$3-50"\t"$3+50"\t"$1"\t100""\t"$4}' > TES_enriched50.bed

#####intersect the DRS_TES 
conda activate isoseq3

####intersect with features on both strands
bedtools intersect -a TES_enriched.bed -b DRS_Peak.bed -wao > TESEnriched_DRS_Intersect_bothStrands
bedtools intersect -a TES_enriched5.bed -b DRS_Peak.bed -wao > TESEnriched5_DRS_Intersect_bothStrands
bedtools intersect -a TES_enriched10.bed -b DRS_Peak.bed -wao > TESEnriched10_DRS_Intersect_bothStrands
bedtools intersect -a TES_enriched20.bed -b DRS_Peak.bed -wao > TESEnriched20_DRS_Intersect_bothStrands
bedtools intersect -a TES_enriched50.bed -b DRS_Peak.bed -wao > TESEnriched50_DRS_Intersect_bothStrands

####May 18th, 2021#################################################

####generate gene list with ployA sites in atRTD3
bedtools intersect -a TES_enriched.bed -b DRS_Peak.bed -wao > TESEnriched_DRS_Intersect_bothStrands

conda deactivate

###24,927 (49.93%) significant REGLs located within the DRS peaks
cat  TESEnriched_DRS_Intersect_bothStrands | awk '$7!="."{print $12}'| sort | uniq | wc -l

###33,840(67.5%) significant REGLs located within the DRS peaks
cat  TESEnriched5_DRS_Intersect_bothStrands | awk '$7!="."{print $12}'| sort | uniq | wc -l
###36,330 (72.8%)
cat  TESEnriched10_DRS_Intersect_bothStrands | awk '$7!="."{print $12}'| sort | uniq | wc -l
##41096 (82.3%)
cat  TESEnriched20_DRS_Intersect_bothStrands | awk '$7!="."{print $12}'| sort | uniq | wc -l
##45,931 (92%)
cat  TESEnriched50_DRS_Intersect_bothStrands | awk '$7!="."{print $12}'| sort | uniq | wc -l
###REGL 12,305 TES sites in 5531 additional genes 
cat  TESEnriched50_DRS_Intersect_bothStrands | awk '$7=="."{print $4}'| wc -l
cat  TESEnriched50_DRS_Intersect_bothStrands | awk '$7=="."{print $4}'| sort | uniq | wc -l
#### 13,065 genes with TES identified in both datasts, 16728-13065=3,663
cat  TESEnriched50_DRS_Intersect_bothStrands | awk '$7!="."{print $4}'| sort | uniq | wc -l


###30,981 signficant RSGLs from 8,088 genes located within the peak regions that are identified as TSS sites in tpc
cat TSSEnriched_TpcPeakArea_Intersect_bothStrands | grep Peak | wc -l

##Compute two-proportions z-test
res <- prop.test(x = c(9326, 30981), n = c(79706, 43254))


##Compute two-proportions z-test on enriched motifs
res <- prop.test(x = c(6976, 3603), n = c(61015, 79707))


###8,445 (90.5%) peak areas were detected
cat TSSEnriched_TpcPeakArea_Intersect_bothStrands | grep Peak | cut -f10 | sort | uniq | wc -l
###

# #####filtering out all the polyA TES sites (712200, 98.38% of TES retained)

cat TES_histogram | awk 'BEGIN{while(getline<"TES_polyA"){if($4=="+"){a[$1][$3][$4]=1}else{a[$1][$2][$4]=1}}}{if(a[$1][$2][$3]!=1){print}}'> TES_histogram_Filtered
# ###(48% filtered TES supported by 1 read)
 ln=`cat TES_histogram_Filtered | wc -l`
# cat TES_histogram_Filtered | cut -f4 | sort | uniq -c | awk -v n=$ln '{print $2"\t"$1"\t"$1/n}'| sort -n > TES_histogram_Filtered_Stats


###sliding window of 11
rm TES_histogram_Filtered_10
for i in `cut -f1 TES_histogram_Filtered | sort | uniq`
do
cat TES_histogram_Filtered | grep ${i} > temp.txt
cat temp.txt | awk 'BEGIN{i=1;while(getline<"temp.txt"){a[i]=$2;b[i]=$4; i++}}{j=NR; hs=$4;while(j>1&&c[j]==c[NR]&&a[NR]-a[j-1]<=5){hs=hs+b[j-1];j--};j=NR; while(j+1<i&&c[j+1]==c[NR]&&a[j+1]-a[NR]<=5){hs=hs+b[j+1];j++};print $1"\t"$2"\t"$3"\t"hs}'>>TES_histogram_Filtered_10
done
rm temp.txt
###(12% filtered TES supported by 1 read), 626,390 TESs support by > 1 read
ln=`cat TES_histogram_Filtered_10 | wc -l`
cat TES_histogram_Filtered_10 | cut -f4 | sort | uniq -c | awk -v n=$ln '{print $2"\t"$1"\t"$1/n}'| sort -n > TES_histogram_Filtered_10_Stats


##############transcript starting site


###TSS from teloprime libraries only 
less ../../temp2 | awk '{if($4=="+"){print $1"\t"$2"\t"$4}else{print $1"\t"$3"\t"$4}}'| sort | uniq -c | awk '{print $2"\t"$3"\t"$4"\t"$1}'| sort -k1,1 -k2,2n >TSS_histogram
###(57.3% TSS supported by 1 read)
ln=`cat TSS_histogram | wc -l`
cat TSS_histogram | cut -f4 | sort | uniq -c | awk -v n=$ln '{print $2"\t"$1"\t"$1/n}'| sort -n > TSS_histogram_Stats

###April 10th, 2020
####for high abundance transcripts, the each TSS and TES will be tested by a fisher exact test


###input: merged50.bed TSS_histogram
cat ../merged.bed | awk '{split($4, a, ";");if($6=="+"){b[$1][$2][$6]=a[1];print $1"\t"$2"\t"$6"\t"b[$1][$2][$6]}else{b[$1][$3][$6]=a[1];print $1"\t"$3"\t"$6"\t"b[$1][$3][$6]}}'| sort | uniq > TSS_gene

cat TSS_histogram | awk 'BEGIN{while(getline<"TSS_gene"){b[$1][$2][$3]=$4}}{print b[$1][$2][$3]"\t"$0}' | sort >  TSS_histogram_gene
#### Fisher exact test using R

#conda create -n gmp

#conda activate gmp
#conda install -c conda-forge r-gmp

R
getwd() 		#get working directory

rm(list=ls()) 	#remove all variables in the current session
#install.packages('gmp')
library(gmp)
#set working directory 
###read in the transcript coordinates
TSS_histogram_gene<-read.table("TSS_histogram_gene", header=F, as.is=T, sep="\t", comment.char="", strip.white=TRUE)
#TransCoord<-read.table("TransCoord_10e2", header=F, as.is=T, sep="\t", comment.char="", strip.white=TRUE)
###get the SD for smaller coordinate and the bigger coordinate of each gene 
TSS_gene_sum<-aggregate(TSS_histogram_gene[,5], by=list(TSS_histogram_gene[,1]), FUN=sum)
TSS_gene_average<-aggregate(TSS_histogram_gene[,5], by=list(TSS_histogram_gene[,1]), FUN=mean)

###pvalue for each site
pv <- rep(1, nrow(TSS_histogram_gene))
###number of locations (TSS) of each gene
loc <- rep(0, nrow(TSS_histogram_gene))
###total number of reads in a gene
Sr <- rep(0, nrow(TSS_histogram_gene))
###average number of reads per site in a gene
Ar<- rep(0, nrow(TSS_histogram_gene))

####when assigning n reads to m locations, for each location, the probability of having k reads in this postions is factorial(n)/(factorial(n-k)*factorial(k))*(1/m)^k*((m-1)/m)^(n-k)
###choose k out of n reads, the probability of the these k reads assigning to the same location is (1/m)^k, the probability that the rest of the reads (n-k) being assigned to other locations is ((m-1)/m)^(n-k).

for (i in 1:nrow(TSS_histogram_gene))
#for (i in 1:151)
{
print(i)
##total number of TSS sites
N_sites<-length(which(TSS_histogram_gene[ ,1]==TSS_histogram_gene[i,1]));
###number of reads at the current location
Reads1<-TSS_histogram_gene[i,5];
####number of reads at all TSS locations for this gene
Reads2<-TSS_gene_sum[which(TSS_gene_sum[ ,1]==TSS_histogram_gene[i,1]),2]
##when assigning n reads to m locations, for each location, the probability of having k reads in this postions is factorial(n)/(factorial(n-k)*factorial(k))*(1/m)^k*((m-1)/m)^(n-k)
#pv[i]<-factorial(Reads2)/(factorial(Reads2-Reads1)*factorial(Reads1))*(1/N_sites)^Reads1*((N_sites-1)/N_sites)^(Reads2-Reads1)

pv[i] <-as.numeric(factorialZ(Reads2)/(factorialZ(Reads2-Reads1)*factorialZ(Reads1))*(1/N_sites)^Reads1*((N_sites-1)/N_sites)^(Reads2-Reads1))

loc[i]<-N_sites
Sr[i]<-Reads2
Ar[i]<-Reads2/N_sites
}

TSS_prob<-cbind(TSS_histogram_gene, pv, loc, Sr, Ar)
names(TSS_prob)<- c("Gene","Chr", "TSS_site","strand", "reads", "pv", "#loc", "totalReads", "AverageReads")



write.table(TSS_prob, file="TSS_prob.txt", row.names = F,col.names = T, quote = FALSE, sep ="\t")

write.table(cbind(TSS_gene_sum, TSS_gene_average), file="TSS_gene_sum_average.txt", row.names = T,col.names = T, quote = FALSE, sep ="\t")

save.image(file = "TSS.RData", version = NULL, ascii = FALSE,compress = FALSE, safe = TRUE)

load('TSS.RData')


####total number of TSS from merged files (616,593)
dim(TSS_prob)
######total enriched TSS (49,246) from 15,822 genes ()
Ind<-which(TSS_prob$pv<0.01&TSS_prob$reads>TSS_prob$AverageReads)
####get the number of total TSS sites for the genes with enriched TSS sites (529,114, which is 85.8% of total TSS sites)
length(which((TSS_prob[,1]) %in% unique(TSS_prob[Ind, 1])))

###get the indexes of the genes with enriched TSS
Ind_GeneTSSEnriched<-match(unique(TSS_prob[Ind, 1]), TSS_gene_sum[,1])

###
quantile(TSS_gene_sum[Ind_GeneTSSEnriched,2], probs = c(0:10)/10)
quantile(TSS_gene_sum[-Ind_GeneTSSEnriched,2], probs = c(0:10)/10)

d<-density(TSS_gene_sum[Ind_GeneTSSEnriched,2],na.rm = T)
d1<-density(TSS_gene_sum[-Ind_GeneTSSEnriched,2],na.rm = T)
pdf(file="gene_Read_density1000.pdf")
plot(d, xlim=c(1, 1000), ylim=c(0,0.21))
lines(d1, col="red")
dev.off()


####
gene_TSSLoci<-unique(TSS_prob[, c(1,7)])
Ind_GeneTSSEnriched2<-match(unique(TSS_prob[Ind, 1]), gene_TSSLoci[,1])

quantile(gene_TSSLoci[Ind_GeneTSSEnriched2,2], probs = c(0:10)/10)
quantile(gene_TSSLoci[-Ind_GeneTSSEnriched2,2], probs = c(0:10)/10)


d<-density(gene_TSSLoci[Ind_GeneTSSEnriched2,2],na.rm = T)
d1<-density(gene_TSSLoci[-Ind_GeneTSSEnriched2,2],na.rm = T)
pdf(file="gene_TSSloc_density100.pdf")
plot(d, xlim=c(1, 100), ylim=c(0,0.3))
lines(d1, col="red")
dev.off()

#####shell script
#####adding the reads over the window of 11nt
cat TSS_prob.txt | awk 'BEGIN{while(getline<"TSS_histogram_10"){a[$1][$2][$3]=$4}}{if(NR==1){print $0"\tReads_Window10"}else{print $0"\t"a[$2][$3][$4]}}'> TSS_prob1.txt

####back in R 
#####load in the new TSS file
TSS_prob1<-read.table("TSS_prob1.txt", header=T, as.is=T, sep="\t", comment.char="", strip.white=TRUE)

######TSS that are enriched using probability of 0.05
Ind<-which(TSS_prob1$pv<0.05&TSS_prob1$reads>TSS_prob1$AverageReads)
##&TSS_prob1$Reads_Window10>=2

####number of genes with enriched TSS (17,098 genes)
length(unique(TSS_prob1[Ind, 1]))

####get the number of total TSS sites for the genes with enriched TSS sites (550,022, which is 89.2% of total TSS sites)
length(which((TSS_prob1[,1]) %in% unique(TSS_prob1[Ind, 1])))

######get all the TSS sites from Genes with no enriched TSS (66,571 TSS from 15,858 genes)
GeneNotEnrichedInd<-which(!(TSS_prob1[,1] %in% unique(TSS_prob1[Ind, 1])))
###get the genes that are not enriched (15,858 genes)
GeneNotEnriched<-unique(TSS_prob1[GeneNotEnrichedInd,1])


######get statistics on the total number of reads
#TSS_tReads<-unique(TSS_prob1[Ind, c(1,8)])
###total read quantiles for genes with enriched TSS
quantile(unique(TSS_prob1[Ind, c(1,8)])[,2], probs = c(0:10)/10)
##0%   10%   20%   30%   40%   50%   60%   70%   80%   90%  100%
# 7    23    37    54    78   110   155   227   357   725 48110
###total read quantiles for genes with no enriched TSS
quantile(unique(TSS_prob1[GeneNotEnrichedInd, c(1,8)])[,2], probs = c(0:10)/10)
## 0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100%
## 1    1    1    1    1    2    3    4    7   13  172

###total TSS sites quantiles for genes with enriched TSS
quantile(unique(TSS_prob1[Ind, c(1,7)])[,2], probs = c(0:10)/10)

###total TSS sites quantiles for genes with no enriched TSS
quantile(unique(TSS_prob1[GeneNotEnrichedInd, c(1,7)])[,2], probs = c(0:10)/10)
## 0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100%
## 1    1    1    1    1    2    3    4    7   13  172

###total TSS sites quantiles for genes with enriched TSS after filtering
quantile(as.data.frame(table(TSS_prob1[Ind,1]))$Freq, probs = c(0:10)/10)


#####stratification


###apply a window for enriched TSS
TSS_prob2<-TSS_prob1[order(TSS_prob1$Chr, TSS_prob1$TSS_site, decreasing=F),]

Ind1<-which(TSS_prob2$pv<0.05&TSS_prob2$reads>TSS_prob2$AverageReads)

####enriched TSS
TSS_enriched<-TSS_prob2[Ind1, ]
write.table(TSS_enriched, file="TSS_enriched.txt", row.names = F,col.names = T, quote = FALSE, sep ="\t")
####non-enriched TSS
write.table(TSS_prob2[-Ind1, ], file="TSS_NonEnriched.txt", row.names = F,col.names = T, quote = FALSE, sep ="\t")

####

Ind_w <- rep(0, nrow(TSS_prob2))
for (i in Ind1)
{
print(i);
Ind_w[i]<-1
j<-i-1
while(abs(TSS_prob2$TSS_site[i]-TSS_prob2$TSS_site[j])<=50&TSS_prob2$Chr[i]==TSS_prob2$Chr[j]&TSS_prob2$strand[i]==TSS_prob2$strand[i]&j>1)
{
#print(j)
Ind_w[j]<-1
j<-j-1
}

j<-i+1;
while(abs(TSS_prob2$TSS_site[i]-TSS_prob2$TSS_site[j])<=50&TSS_prob2$Chr[i]==TSS_prob2$Chr[j]&TSS_prob2$strand[i]==TSS_prob2$strand[i]&j<nrow(TSS_prob2))
{Ind_w[j]<-1
j<-j+1}
}

####number of TSSs within the 100nt of the enriched TSS (387,700) 
length(which(Ind_w==1))
write.table(TSS_prob2[which(Ind_w==1),], file="TSS_enriched_window.txt", row.names = F,col.names = T, quote = FALSE, sep ="\t")


####non-enriched TSS with more than 2 reads (25,390 TSS sites)
Ind2<-which(!(TSS_prob1[,1] %in% unique(TSS_prob1[Ind, 1]))&TSS_prob1[,10]>=2)
TSS_Nenriched<-TSS_prob1[Ind2, ]

####number of genes with no enriched TSS after read filtering
length(unique(TSS_prob1[Ind2, 1]))

###total TSS sites quantiles for genes with non enriched TSS after filtering
quantile(as.data.frame(table(TSS_prob1[Ind2,1]))$Freq, probs = c(0:10)/10)

write.table(TSS_Nenriched, file="TSS_Nenriched.txt", row.names = F,col.names = T, quote = FALSE, sep ="\t")



conda deactivate

######concatenate TSS from enriched window and non enriched TSS with reads>2 (413,089 TSSs)

cat TSS_enriched_window.txt TSS_Nenriched.txt > TSS_highConf

########June 12th, 2020#########
####compare the enriched TSS with tpc TSS results 
####
###1. convert tpc results in to bed files

# 1. chrom - The name of the chromosome (e.g. chr3, chrY, chr2_random) or scaffold (e.g. scaffold10671).
# 2. chromStart - The starting position of the feature in the chromosome or scaffold. The first base in a chromosome is numbered 0.
# 3. chromEnd - The ending position of the feature in the chromosome or scaffold. The chromEnd base is not included in the display of the feature, however, the number in position format will be represented. For example, the first 100 bases of chromosome 1 are defined as chrom=1, chromStart=0, chromEnd=100, and span the bases numbered 0-99 in our software (not 0-100), but will represent the position notation chr1:1-100. Read more here.
# 4. name - Defines the name of the BED line. This label is displayed to the left of the BED line in the Genome Browser window when the  track is open to full display mode or directly to the left of the item in pack mode.
#5. score - A score between 0 and 1000. If the track line useScore attribute is set to 1 for this annotation data set, the score value will determine the level of gray in which this feature is displayed (higher numbers = darker gray). This table shows the Genome Browsers translation of BED score values into shades of gray: 
# 6. strand - Defines the strand. Either "." (=no strand) or "+" or "-".
# 7.thickStart - The starting position at which the feature is drawn thickly (for example, the start codon in gene displays). When there is no thick part, thickStart and thickEnd are usually set to the chromStart position.
# 8.thickEnd - The ending position at which the feature is drawn thickly (for example the stop codon in gene displays).
# 9.itemRgb - An RGB value of the form R,G,B (e.g. 255,0,0). If the track line itemRgb attribute is set to "On", this RBG value will determine the display color of the data contained in this BED line. NOTE: It is recommended that a simple color scheme (eight colors or less) be used with this attribute to avoid overwhelming the color resources of the Genome Browser and your Internet browser.
# 10. blockCount - The number of blocks (exons) in the BED line.
# 11. blockSizes - A comma-separated list of the block sizes. The number of items in this list should correspond to blockCount.
# 12. blockStarts - A comma-separated list of block starts. All of the blockStart positions should be calculated relative to chromStart. The number of items in this list should correspond to blockCount.

###1.chrom;2.start;3. end; 4. name; 5. score 1000; 6. strand;
###detected peaks
dos2unix tpc_TSS_allPeaks.txt (9,326)
cat tpc_TSS_allPeaks.txt | awk 'NR>1{print $1"\t"$3"\t"$4"\t"$13"\t100""\t"$2}' > TpcPeakArea.bed
###only get the mode postions ()
cat tpc_TSS_allPeaks.txt | awk 'NR>1{print $1"\t"$6"\t"$6"\t"$13"\t100""\t"$2}' > TpcPeak.bed

#####generate the width of the peaks
cat tpc_TSS_allPeaks.txt | awk 'NR>1{print $4-$3}'| sort -n > PeakWidth 
cat tpc_AllPeak.txt | awk 'NR>1{print $4-$3}'| sort -n > PeakWidth_all

R
TSS_wd<-read.table("PeakWidth_all", header=F, as.is=T, sep="\t", comment.char="", strip.white=TRUE)
TSS_wd1<-read.table("PeakWidth", header=F, as.is=T, sep="\t", comment.char="", strip.white=TRUE)

quantile(TSS_wd[,1], probs = c(0:10)/10)

quantile(TSS_wd1[,1], probs = c(0:10)/10)
 ####
 0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100%
   0   15   30   40   50   60   69   81   98  123  707

###all peaks (79,706)
dos2unix tpc_AllPeak.txt
cat tpc_AllPeak.txt | awk 'NR>1{print $1"\t"$3"\t"$4"\t"$13"\t100""\t"$2}' > TpcPeakAreaAll.bed

###TES peak from DRS ()
dos2unix TES_DRS.txt
cat TES_DRS.txt | sed 's/fwd/+/g' | sed 's/rev/-/g' | awk 'NR>1{print $2"\t"$4"\t"$4"\t"$3"\t100""\t"$1}' > DRS_Peak.bed


###TSS sites
cat TSS_enriched.txt | awk 'NR>1{print $2"\t"$3"\t"$3"\t"$1"\t100""\t"$4}' > TSS_enriched.bed

#####intersect the tpc-TSS 
conda activate isoseq3

####intersect with features on both strands
bedtools intersect -a TSS_enriched.bed -b TpcPeakAreaAll.bed -wao > TSSEnriched_TpcPeakAreaAll_Intersect_bothStrands
bedtools intersect -a TSS_enriched.bed -b TpcPeakArea.bed -wao > TSSEnriched_TpcPeakArea_Intersect_bothStrands
bedtools intersect -a TSS_enriched.bed -b TpcPeak.bed -wao > TSSEnriched_TpcPeak_Intersect_bothStrands
conda deactivate

###43,254 (70.9%) significant RSGLs located within the peak region detected in tpc
cat TSSEnriched_TpcPeakAreaAll_Intersect_bothStrands | grep Peak | wc -l

###30,981 signficant RSGLs from 8,088 genes located within the peak regions that are identified as TSS sites in tpc
cat TSSEnriched_TpcPeakArea_Intersect_bothStrands | grep Peak | wc -l

##Compute two-proportions z-test
res <- prop.test(x = c(9326, 30981), n = c(79706, 43254))

###8,445 (90.5%) peak areas were detected
cat TSSEnriched_TpcPeakArea_Intersect_bothStrands | grep Peak | cut -f10 | sort | uniq | wc -l
###



cat TSSEnriched_TpcPeak_Intersect_bothStrands | grep Peak

###For 9,326 detected TSS peaks,  6,563 (70.4%) TSS peak mode (the most abundant position within that peak) colocated with the significant RSGLs detected as non-random   
 cat TSSEnriched_TpcPeak_Intersect_bothStrands | grep Peak | cut -f10 | sort | uniq | wc -l


####07 December 2021
####TSS comparison with Nielsen and Thomas paper

cat Nielsen_TSS.txt | sed "1d" | sed  s/"ChrMt"/"ChrM"/g | sed s/"ChrPt"/"ChrC"/g  | sort -k1,1 -k2,2n | awk -F"\t" '{print "Chr"$1"\t"$2"\t"$3"\t Peak"NR"_"$9"\t100\t"$4}' > Nielsen_TSS.bed
#cat Nielsen_TSS.txt | sed "1d" | awk '{print "Chr"$1"\t"$6-5"\t"$6+5"\tPeak"NR_"\t100\t"$4}'> Nielsen_Peak05.bed
#cat Nielsen_TSS.txt | sed "1d" | awk '{print "Chr"$1"\t"$6-10"\t"$6+10"\tPeak"NR"\"t100\t"$4}'> Nielsen_Peak10.bed

###
bedtools intersect -a TSS_enriched.bed -b Nielsen_TSS.bed -wao > TSSEnriched_Nielsen_Intersect_bothStrands
#bedtools intersect -a TSS_enriched.bed -b Nielsen_Peak05.bed -wao > TSSEnriched_NielsenPeak05_Intersect_bothStrands
#bedtools intersect -a TSS_enriched.bed -b Nielsen_Peak10.bed -wao > TSSEnriched_NielsenPeak10_Intersect_bothStrands

###55,737 (91.35% of total 61,014) significant RSGLs located within the peak region detected in Nielsen
cat TSSEnriched_Nielsen_Intersect_bothStrands | grep Peak | awk '$6==$12{print}'| wc -l
###18,398 out of 96,232 peaks 
cat TSSEnriched_Nielsen_Intersect_bothStrands | grep Peak | awk '$6==$12{print $10}'| sort | uniq | wc -l
###16,353 genes that enriched TSS have been detected
cat TSSEnriched_Nielsen_Intersect_bothStrands | grep Peak | awk '$6==$12{split($10,a, "_"); print a[2]}'| sort | uniq | wc -l
####21,359 genes with TSS clusters using TSS-seq
cat Nielsen_TSS.txt | sed "1d" | awk -F "\t" '{print $9}' | sort | uniq | wc -l
###17,098 genes in the TSS enriched sets
cat TSS_enriched.bed | cut -f4 | sort | uniq | wc -l



##########comparison with Thomas paper

unzip TSS_Thomas2020.zip -d  TSS_Thomas

cd TSS_Thomas/

cat *.txt | grep -v "seqnames" | sort -k1,1 -k2,2n| awk '{print "Chr"$1"\t"$2"\t"$3"\tPeak"NR"\t100\t"$4}'> ../Thomas_TSS.bed

####7,495 sites of 
bedtools intersect -a TSS_enriched.bed -b Thomas_TSS.bed -wao > TSSEnriched_Thomas_Intersect_bothStrands
###2,934 out of 4,637 TSS clusters
cat TSSEnriched_Thomas_Intersect_bothStrands | grep Peak | awk '$6==$12{print $10}'| sort | uniq | wc -l



####the output of the intersections between Iso-seq and Araport
###1. geneName_Isoseq; 2. transcriptID_Isoseq; 3. strand Isoseq; 4. Isoseq tx start coordinate; 5. Isoseq tx end coordinate;
###6. isoseq tx number of exons; 7. percentage of overlap with Araport gene (overlap/gene length); 
###8. Araport gene id; 9. Araport strand; 10. gene start coordindate; 11. gene end coordinate; 
###12. overlap percentage (overlap/gene length); 13. overlap length

cat TSSEnriched_TpcPeakAreaAll_Intersect_bothStrands  | cut -f4,6,7,8,10,16,17,19,21,22 | awk -F"\t" '{split($9,a,";");split($1, b, ";");print b[1]"\t"b[2]"\t"$2"\t"$3"\t"$4"\t"$5"\t"$10/($4-$3+1)"\t"a[1]"\t"$8"\t"$6"\t"$7"\t"$10/($7-$6+1)"\t"$10}'> IsoseqatRTD2_Araport11_gene_annotation_bothStrands

#######take the gene doesn't overlap with atIso+atRTD2 on the same strand (38,194-28,598=9,596 genes)
###28,598 overlapped genes
cat IsoseqatRTD2_Araport11_gene_annotation_bothStrands | awk '$3==$9{split($8,a,"=");print a[2]}'| sort | uniq > AraportOverlappedGenes



###sliding window of 11 (26.14% TSS supported by 1 read)
####take one chr at a time
rm TSS_histogram_10
for i in `cut -f1 TSS_histogram | sort | uniq`
do
cat TSS_histogram | grep ${i} > temp.txt
cat temp.txt | awk 'BEGIN{i=1;while(getline<"temp.txt"){a[i]=$2;b[i]=$4; i++}}{j=NR; hs=$4;while(j>1&&c[j]==c[NR]&&a[NR]-a[j-1]<=5){hs=hs+b[j-1];j--};j=NR; while(j+1<i&&c[j+1]==c[NR]&&a[j+1]-a[NR]<=5){hs=hs+b[j+1];j++};print $1"\t"$2"\t"$3"\t"hs}'>>TSS_histogram_10
done
rm temp.txt
###455,420 TSS with >1 read
ln=`cat TSS_histogram_10 | wc -l`
cat TSS_histogram_10 | cut -f4 | sort | uniq -c | awk -v n=$ln '{print $2"\t"$1"\t"$1/n}'| sort -n > TSS_histogram_10_Stats

###May 25th, 2020
###retain transcripts that are supported by TES/TSS (1,674,795) 

cat merged_LDE_30_30_filtered1.bed | awk 'BEGIN{while(getline<"TSS_highConf"){TSS[$2][$3][$4]=1;};while(getline<"TES_highConf"){TES[$2][$3][$4]=1;}}{if($6=="+"){if(TSS[$1][$2][$6]==1&&TES[$1][$3][$6]==1){print}}else{if(TSS[$1][$3][$6]==1&&TES[$1][$2][$6]==1){print}}}' > merged_LDE_30_30_filtered_HC_ends.bed

#####get the removed tx due to poor support of TSS/TES (447,114 removed 20% of 2,121,909 total transcripts)
cat merged_LDE_30_30_filtered1.bed | awk 'BEGIN{while(getline<"TSS_highConf"){TSS[$2][$3][$4]=1;};while(getline<"TES_highConf"){TES[$2][$3][$4]=1;}}{if($6=="+"){if(TSS[$1][$2][$6]==1&&TES[$1][$3][$6]==1){}else{print}}else{if(TSS[$1][$3][$6]==1&&TES[$1][$2][$6]==1){}else{print}}}' > RemovedTranscrpits_HC_ends.bed


###Jan 6th, 2019 
######get the genes being removed
###32,962 genes before ends filtering
cut -f4 merged_LDE_30_30_filtered1.bed | awk '{split($1, a, ";");print a[1]}'| sort | uniq > merged_filtered1_genes
###21,409 genes after ends filtering
cut -f4 merged_LDE_30_30_filtered_HC_ends.bed | awk '{split($1, a, ";");print a[1]}'| sort | uniq > merged_filtered_HC_ends_genes

### 11,553 genes removed
comm -23 merged_filtered1_genes merged_filtered_HC_ends_genes > filtered1_genes


# ######get the transcripts being removed
#####2,121,909 tx before TES/TSS filtering
 cut -f4 merged_LDE_30_30_filtered1.bed | awk '{split($1, a, ";");print a[2]}'| sort | uniq > merged_filtered1_transcripts
 ####1,674,795 tx after TES/TSS filtering
 cut -f4 merged_LDE_30_30_filtered_HC_ends.bed | awk '{split($1, a, ";");print a[2]}'| sort | uniq > merged_filtered_HC_ends_transcripts

# ###447,114 transcripts removed
 comm -23 merged_filtered1_transcripts merged_filtered_HC_ends_transcripts > filtered1_transcripts

###get the Araport annotations of the removed genes (11,553)
cat ../Isoseq_gene_annotation_bothStrands | awk 'BEGIN{while(getline<"filtered1_genes"){a[$1]="T"};while(getline<"filtered1_transcripts"){b[$1]="T"}}a[$1]=="T"&&b[$2]=="T"{print}'> Isoseq_annt_filtered1_genes

####genes covers Araport models by >50% (mutually) on the same strand 
###2483 genes
cat Isoseq_annt_filtered1_genes | awk '$12>0.5&&$7>0.5&&$3==$9{print $1}'| sort | uniq | wc -l
###7398 transcripts
cat Isoseq_annt_filtered1_genes | awk '$12>0.5&&$7>0.5&&$3==$9{print $2}'| sort | uniq | wc -l
###2107 genes overlap by >50%, but on different strand (potential novel long non-coding RNAs?)
cat Isoseq_annt_filtered1_genes | awk '$12>0.5&&$7>0.5&&$3!=$9{print $1}'| sort | uniq | wc -l
###7398 transcript that overlap with Araport model by 50% are kept
 cat Isoseq_annt_filtered1_genes | awk '$12>0.5&&$7>0.5&&$3==$9{print $2}'| sort | uniq > TranscriptOverlapAraport


###combined with low abundance but with Araport model (23,892 genes, 1,682,193 transcripts)

cat merged_filtered_HC_ends_transcripts TranscriptOverlapAraport | sort | uniq > transcripts_tokeep
####23,892 genes 
less transcripts_tokeep | awk '{split($1,a, "."); print a[1]}'| sort | uniq | wc -l

cat merged_LDE_30_30_filtered1.bed | awk 'BEGIN{while(getline<"transcripts_tokeep"){a[$1]="T"}}{split($4, b, ";");if(a[b[2]]=="T"){print}}'> merged_LDE_30_30_filtered2.bed

cat merged_LDE_30_30_filtered1.bed | awk 'BEGIN{while(getline<"transcripts_tokeep"){a[$1]="T"}}{split($4, b, ";");if(a[b[2]]!="T"){print}}'> merged_LDE_30_30_filtered2_removed.bed


###June 27th, 2020
########impact of TSS/TES filtering on single exon genes

####multi-exon genes 19,343, single exon genes 32,962-19,343=13,619
less merged_LDE_30_30_filtered1.bed | awk -F"\t" '$10>1{split($4,a, ";"); print a[1]}'| sort | uniq | wc -l
##32962
less merged_LDE_30_30_filtered1.bed | awk -F"\t" '{split($4,a, ";"); print a[1]}'| sort | uniq | wc -l

#####after TSS/TES filtering
####multi-exon genes 16,932, single exon genes 21,409-16,932=4,477 (32.9%)
less merged_LDE_30_30_filtered_HC_ends.bed | awk -F"\t" '$10>1{split($4,a, ";"); print a[1]}'| sort | uniq | wc -l
##21,409
less merged_LDE_30_30_filtered_HC_ends.bed | awk -F"\t" '{split($4,a, ";"); print a[1]}'| sort | uniq | wc -l


#####after TSS/TES filtering + overlapped genes with Araport
####multi-exon genes 18,314, single exon genes 23,892-18,314=5,578
less merged_LDE_30_30_filtered2.bed | awk -F"\t" '$10>1{split($4,a, ";"); print a[1]}'| sort | uniq | wc -l
##23,892
less merged_LDE_30_30_filtered2.bed | awk -F"\t" '{split($4,a, ";"); print a[1]}'| sort | uniq | wc -l


##23,892 genes, 1,682,193 transcripts (142,526 tx removed)
cut -f4 merged_LDE_30_30_filtered2.bed | awk '{split($1, a, ";");print a[1]}'| sort | uniq | wc -l
cut -f4 merged_LDE_30_30_filtered2.bed | awk '{split($1, a, ";");print a[1]}'| sort | uniq > merged_LDE_30_30_filtered2_genes
cut -f4 merged_LDE_30_30_filtered2.bed | awk '{split($1, a, ";");print a[2]}'| sort | uniq | wc -l


###run TAMA merge to merge transcripts with similar UTRs


######june 18th
#####generate atIso
###generate filelist for TAMA merge
rm filelist.txt filelist1.txt

ls merged_LDE_30_30_filtered_HC_ends.bed | awk '{split($1,a,".");print $1"\tcapped\t1,1,1\t"a[1];}'>>filelist.txt

cat filelist.txt | awk '{print $1"\t"$2"\t"$3"\t"$4}'> filelist1.txt

####merge transcripts allowing 50nt differences at TSS/TES
nohup python /home/rz41242/software/TAMA/tama/tama_merge.py -f filelist1.txt -p atIso_merged50 -m 0 -a 50 -z 50 -d merge_dup &

##21,853 genes, 127,165 transcripts

cut -f4 atIso_merged50.bed | awk '{split($1, a, ";");print a[1]}'| sort | uniq | wc -l

cut -f4 atIso_merged50.bed | awk '{split($1, a, ";");print a[2]}'| sort | uniq | wc -l

######compare atIso, atRTD2 and Araport11 using TAMA merge
###correct bed files for Araport11
####Chr1    23311   24099   AT1G03993.1     0       -       23311   24099   0       1       788,    0,
##bed12 files must have the gene ID's and transcript ID's formatted as such "gene_id;transcript_id" in the 4th column.
###The gene ID must be the first subfield and the subfields must be delimited with a semicolon (;).



rm filelist.txt 
###atIso capped, atRTD2, Araport11 uncapped
ls atIso_merged50.bed AtRTD2_19April2016.bed Araport11.201606_formatted.bed | sort -r | awk '{split($1,a,".");n=split(a[1],b, "/");if(NR==1){print $1"\tcapped\t1,1,1\t"b[n]}else{print $1"\tno_cap\t2,1,2\t"b[n]}}'>>filelist.txt

####merge transcripts allowing 50nt differences at TSS/TES
nohup python /home/rz41242/software/TAMA/tama/tama_merge.py -f filelist.txt -p merged50_compareAll -m 0 -a 50 -z 50 -d merge_dup &

###compare the number of transcripts shared by different annotations
###209,508 tx after merge all three (atIso 127,165 tx; atRTD2 82,190; Araport 59,775)
less merged50_compareAll_merge.txt | cut -f4 | awk '{split($1, a,";");print a[1]}'| sort | uniq | wc -l

less merged50_compareAll_merge.txt | cut -f4 | awk '{split($1, a,";");print a[1]"\t"a[2]}'| awk 'BEGIN{src="";mg=""}{if(mg!=$1){print mg"\t"src; mg=$1;src=$2}else{src=src";"$2}}END{print mg"\t"src}'

##Araport11;atIso;AtRTD2
###draw a venn diagram
###5,369 shared by all three
less merged50_compareAll_merge.txt | cut -f4 | awk '{split($1, a,";");print a[1]"\t"a[2]}'| awk 'BEGIN{src="";mg=""}{if(mg!=$1){print mg"\t"src; mg=$1;src=$2}else{src=src";"$2}}END{print mg"\t"src}' | grep Araport11 | grep atIso | grep AtRTD2 | wc -l
####
## 980 shared by Araport11 and atIso
less merged50_compareAll_merge.txt | cut -f4 | awk '{split($1, a,";");print a[1]"\t"a[2]}'| awk 'BEGIN{src="";mg=""}{if(mg!=$1){print mg"\t"src; mg=$1;src=$2}else{src=src";"$2}}END{print mg"\t"src}' | grep Araport11 | grep atIso | grep -v AtRTD2 | wc -l

## 6,167 shared by atRTD2 and atIso
less merged50_compareAll_merge.txt | cut -f4 | awk '{split($1, a,";");print a[1]"\t"a[2]}'| awk 'BEGIN{src="";mg=""}{if(mg!=$1){print mg"\t"src; mg=$1;src=$2}else{src=src";"$2}}END{print mg"\t"src}' | grep -v Araport11 | grep atIso | grep AtRTD2 | wc -l

###42,573 shared by Araport11 and atRTD2
less merged50_compareAll_merge.txt | cut -f4 | awk '{split($1, a,";");print a[1]"\t"a[2]}'| awk 'BEGIN{src="";mg=""}{if(mg!=$1){print mg"\t"src; mg=$1;src=$2}else{src=src";"$2}}END{print mg"\t"src}' | grep Araport11 | grep -v atIso | grep AtRTD2 | wc -l

###28,913 atRTD2
less merged50_compareAll_merge.txt | cut -f4 | awk '{split($1, a,";");print a[1]"\t"a[2]}'| awk 'BEGIN{src="";mg=""}{if(mg!=$1){print mg"\t"src; mg=$1;src=$2}else{src=src";"$2}}END{print mg"\t"src}' | grep -v Araport11 | grep -v atIso | grep AtRTD2 | wc -l

###10,883 Araport11
less merged50_compareAll_merge.txt | cut -f4 | awk '{split($1, a,";");print a[1]"\t"a[2]}'| awk 'BEGIN{src="";mg=""}{if(mg!=$1){print mg"\t"src; mg=$1;src=$2}else{src=src";"$2}}END{print mg"\t"src}' | grep Araport11 | grep -v atIso | grep -v AtRTD2 | wc -l

###114,623 (54.7%) atIso
less merged50_compareAll_merge.txt | cut -f4 | awk '{split($1, a,";");print a[1]"\t"a[2]}'| awk 'BEGIN{src="";mg=""}{if(mg!=$1){print mg"\t"src; mg=$1;src=$2}else{src=src";"$2}}END{print mg"\t"src}' | grep -v Araport11 | grep atIso | grep -v AtRTD2 | wc -l


R

.libPaths("/home/rz41242/software/Rlib")
library(eulerr)

fit2 <- euler(c("atIso" = 114623, "atRTD2" = 28913, "Araport" = 10883, "atIso&atRTD2" = 6167, "atRTD2&Araport" = 42573, "Araport&atIso" = 980, "Araport&atIso&atRTD2" = 5369))

pdf("Venn_Tx.pdf")
plot(fit2, fills = c("skyblue", "pink1", "mediumorchid"), alpha = 0.8, edges = FALSE, labels = list(col = "white", fontsize = 8),quantities = list(fontsize = 8),legend = list(labels = c("atIso", "atRTD2", "Araport")))
dev.off()





#########################################################################################################################

####comparison of splice junctions
cat atIso_merged50_merge.txt | awk -F"\t" '{split($4, a, ";"); split($11, b, ","); split($12, c, ",");d=""; for (i = 1; i < $10; i++){print a[1]"\t"$1"_"c[i]+$7+b[i]+1"_"c[i+1]+$7"_"$6}}'  > SJ_atIso_merged50



###compare the overlaps of the SJs
###atIso SJs
cat SJ_atIso_merged50 | cut -f2 | sort | uniq > SJ_atIso_merged50_sorted
###atRTD2 SJ_RTD2_sorted
###araport SJ_araport_sorted

#total 183,035 SJs in Araport, atRTD2 and atIso
cat SJ_atIso_merged50_sorted SJ_RTD2_sorted SJ_araport_sorted | sort | uniq | wc -l

## 100,275 SJs shared by Araport, atRTD2 and atIso
cat SJ_atIso_merged50_sorted SJ_RTD2_sorted SJ_araport_sorted | sort | uniq -c | awk '$1==3{print}'| wc -l

########put the results into table

rm Temp_Ind
#create index of all files
cat SJ_atIso_merged50_sorted SJ_RTD2_sorted SJ_araport_sorted | sort | uniq  >Temp_Ind
wc -l Temp_Ind
#insert header
cat Temp_Ind | awk 'BEGIN{print "SJ"}{print $0}'>Temp
mv Temp Temp_Ind

rm Temp
#add values to 
#for i in `ls *_Read1_TPM`
for i in `ls SJ_atIso_merged50_sorted SJ_RTD2_sorted SJ_araport_sorted`
do 
cat $i | awk -F"\t" -v file=$i 'BEGIN{c=0;while(getline<"Temp_Ind"){c++;if(c==1){Header=$0}else{A[$1]=1;Entry[$1]=$0}}}{if(NR==1){print Header"\t"file};if(A[$1]==1){RPM[$1]=1}}END{for (x in A){print Entry[x]"\t"RPM[x]} }'> Temp
mv Temp Temp_Ind
done
 
 #remove empty lines and sort
cat Temp_Ind | awk 'NF>0{print}' > temp
#table the header
cat temp | head -n 1 > temp1
#sort the entries except the header
cat temp | tail -n +2 | sort > temp2
#combine header and entries
cat temp1 temp2 |awk -F"\t" '{print}' > SJTable.txt
rm temp temp1 temp2 Temp_Ind

#total 183,035 SJs in Araport, atRTD2 and atIso
 
####100,275 (54.78%) SJs shared by Araport, atIso and atRTD2
cat SJTable.txt | awk -F"\t" '$2==1&&$3==1&&$4==1{print}'| wc -l 
####33,115 SJs shared by Araport,atRTD2 (18.1%) 
cat SJTable.txt | awk -F"\t" '$2==1&&$3!=1&&$4==1{print}'| wc -l
####646 SJs shared by Araport,atIso
cat SJTable.txt | awk -F"\t" '$2==1&&$3==1&&$4!=1{print}'| wc -l 
####8,399 SJs shared by atIso and atRTD2 (4.6%)
cat SJTable.txt | awk -F"\t" '$2!=1&&$3==1&&$4==1{print}'| wc -l
####2,410 SJs unique to araport (1.3%)
cat SJTable.txt | awk -F"\t" '$2==1&&$3!=1&&$4!=1{print}'| wc -l
####28,035 SJs unique to atIso (15%)
cat SJTable.txt | awk -F"\t" '$2!=1&&$3==1&&$4!=1{print}'| wc -l
####10,155 SJs unique to atRTD2 (5.5%)
cat SJTable.txt | awk -F"\t" '$2!=1&&$3!=1&&$4==1{print}'| wc -l


R

.libPaths("/home/rz41242/software/Rlib")
library(eulerr)

fit2 <- euler(c("atIso" = 28035, "atRTD2" = 10155, "Araport" = 2410, "atIso&atRTD2" = 8399, "atRTD2&Araport" = 33115, "Araport&atIso" = 646, "Araport&atIso&atRTD2" = 100275))

pdf("Venn_SJ.pdf")
plot(fit2, fills = c("skyblue", "pink1", "mediumorchid"), alpha = 0.8, edges = FALSE, labels = list(col = "white", fontsize = 8),quantities = list(fontsize = 8),legend = list(labels = c("atIso", "atRTD2", "Araport")))
dev.off()


#########################################################################
####compare the gene coverage between atIso and Araport
####identify novel loci in Araport11


conda activate isoseq3

####intersect with features on both strands
bedtools intersect -a atIso_merged50.bed -b Araport11_2016_gene.gff -wao > atIso_Araport11_Intersect_bothStrands

conda deactivate

###Araport total number of genes 38194

####the output of the intersections between Iso-seq and Araport
###1. geneName_Isoseq; 2. transcriptID_Isoseq; 3. strand Isoseq; 4. Isoseq tx start coordinate; 5. Isoseq tx end coordinate;
###6. isoseq tx number of exons; 7. percentage of overlap with Araport gene (overlap/gene length); 
###8. Araport gene id; 9. Araport strand; 10. gene start coordindate; 11. gene end coordinate; 
###12. overlap percentage (overlap/gene length); 13. overlap length

cat atIso_Araport11_Intersect_bothStrands | cut -f4,6,7,8,10,16,17,19,21,22 | awk -F"\t" '{split($9,a,";");split($1, b, ";");print b[1]"\t"b[2]"\t"$2"\t"$3"\t"$4"\t"$5"\t"$10/($4-$3+1)"\t"a[1]"\t"$8"\t"$6"\t"$7"\t"$10/($7-$6+1)"\t"$10}'> atIso_Araport11_gene_annotation_bothStrands

#######take the gene doesn't overlap with atIso+atRTD2 on the same strand (38,194-28,598=9,596 genes)
###28,598 overlapped genes
###1. gene name; 2. tx id; 3. strand; 4. start; 5. end; 6. number of exons; 7. matched percentage; 8. matched gene id; 9. strand; 10. start; 11 end; 12. matched percentage; 13. overlap length

###Araport overlapped genes 20,663 (coverage >50%), 21,382 (coverage>0); 38,194-21,382=16,812 genes with no coverage/poor coverage
###on the same strand
###coverage> 0.5
cat atIso_Araport11_gene_annotation_bothStrands | awk '$3==$9&&$12>0.5{split($8,a,"=");print a[2]}'| sort | uniq | wc -l
###20,373
cat atIso_Araport11_gene_annotation_bothStrands | awk '$3==$9&&($12>0.3||$7>0.3){print $1}'| sort | uniq > OverlapGene_atIso_Araport
###1480 novel genes in atIso compared to Araport
cat atIso_Araport11_gene_annotation_bothStrands | awk 'BEGIN{while(getline<"OverlapGene_atIso_Araport"){a[$1]=1}}a[$1]!=1{print $1}'| sort | uniq > NovelGene_atIso_Araport

####21,382 
cat atIso_Araport11_gene_annotation_bothStrands | awk '$3==$9{split($8,a,"=");print a[2]}'| sort | uniq | wc -l


###Isoseq overlapped genes 20,194 (coverage >50%), 20,404 (coverage>0); 21,853-21,404=449 genes with no coverage
###on the same strand
###coverage> 0.5
q awk '$3==$9&&$7>0.5{print $1}'| sort | uniq | wc -l
####20,404 
cat atIso_Araport11_gene_annotation_bothStrands | awk '$3==$9{print $1}'| sort | uniq | wc -l





####merge with atRTD2
###Criteria:Transcripts in atRTD2 has to contains a novel SJs to be included
###22 May, 2020
cat /mnt/shared/scratch/rz41242/2017Isoseq/sam/LDE_30_30_HD/FinalComparison/merged50_merge.txt | awk -F"\t" '{split($4, a, ";"); split($11, b, ","); split($12, c, ",");d=""; for (i = 1; i < $10; i++){print a[1]"\t"$1"_"c[i]+$7+b[i]+1"_"c[i+1]+$7"_"$6}}'  > /mnt/shared/scratch/rz41242/2017Isoseq/sam/SplicedJunctions/SJ_merged50

cd /mnt/shared/scratch/rz41242/2017Isoseq/sam/SplicedJunctions

###unique sjs in atIso 144,794 (88.9% of 162,888 passed the SJ filtering)
less SJ_merged50 | cut -f2 | sort | uniq | wc -l

###compare the overlaps of the SJs
cat SJ_merged50 | cut -f2 | sort | uniq > SJ_merged50_sorted

###shared SJs: 115,404, SJs unique to RTD2: 36,540 (24.05% of all RTD2 151,944 SJs) and SJs unique to Iso-seq: 29,390
comm -12 SJ_merged50_sorted SJ_RTD2_sorted | wc -l
comm -23 SJ_merged50_sorted SJ_RTD2_sorted > SJ_merged50_unique
comm -13 SJ_merged50_sorted SJ_RTD2_sorted > atRTD2merged50_unique

####24,830 transcripts in atRTD2 to add
cat SJ_RTD2 |  awk 'BEGIN{while(getline<"atRTD2merged50_unique"){a[$1]="True"}}{if(a[$2]=="True"){print}}'| cut -f1 | sort | uniq > atRTD2Transcripts2add

cat /mnt/shared/scratch/rz41242/2017Isoseq/sam/atRTD2/AtRTD2_19April2016.bed | awk -F"\t" 'BEGIN{while(getline<"atRTD2Transcripts2add"){a[$1]=1}}{split($4, b, ";"); if(a[b[2]]==1){print}}' >  AtRTD2_19April2016_Transcript2include.bed

cp AtRTD2_19April2016_Transcript2include.bed /mnt/shared/scratch/rz41242/2017Isoseq/sam/LDE_30_30_HD/FinalComparison

####merge atIso and atRTD2
###generate filelist for TAMA merge
cd /mnt/shared/scratch/rz41242/2017Isoseq/sam/LDE_30_30_HD/FinalComparison

rm filelist.txt filelist2.txt

###atIso capped, atRTD2 uncapped
ls merged50.bed AtRTD2_19April2016_Transcript2include.bed | sort -r | awk '{split($1,a,".");if(NR==1){print $1"\tcapped\t1,1,1\t"a[1]}else{print $1"\tno_cap\t2,1,2\t"a[1]}}'>>filelist.txt

cat filelist.txt | awk '{$1="/mnt/shared/scratch/rz41242/2017Isoseq/sam/LDE_30_30_HD/FinalComparison/"$1;print $1"\t"$2"\t"$3"\t"$4}'> filelist2.txt

####merge transcripts allowing 50nt differences at TSS/TES
nohup python /home/rz41242/software/TAMA/tama/tama_merge.py -f filelist2.txt -p merged50_atRTD2 -m 0 -a 50 -z 50 -d merge_dup &

##28,717 genes, 156,988 transcripts

cut -f4 merged50_atRTD2.bed | awk '{split($1, a, ";");print a[1]}'| sort | uniq | wc -l
cut -f4 merged50_atRTD2.bed | awk '{split($1, a, ";");print a[2]}'| sort | uniq | wc -l

####generate splice junctions for atIso+atRTD2
cat /mnt/shared/scratch/rz41242/2017Isoseq/sam/LDE_30_30_HD/FinalComparison/merged50_atRTD2_merge.txt | awk -F"\t" '{split($4, a, ";"); split($11, b, ","); split($12, c, ",");d=""; for (i = 1; i < $10; i++){print a[1]"\t"$1"_"c[i]+$7+b[i]+1"_"c[i+1]+$7"_"$6}}'  > /mnt/shared/scratch/rz41242/2017Isoseq/sam/SplicedJunctions/SJ_merged50_atRTD2

####merge Araport11
####Transcripts in Araport or atRTD2 has to contains a novel SJs to be included; Araport Transcripts that contains a loci that is not covered by atIso

##38,194 genes, 59,775 transcripts

cut -f4 /home/rz41242/Projects/2017IsoSeq/genome/Araport/Araport11.201606.bed | awk '{split($1, a, ".");print a[1]}'| sort | uniq | wc -l
cut -f4 /home/rz41242/Projects/2017IsoSeq/genome/Araport/Araport11.201606.bed | awk '{print}'| sort | uniq | wc -l


cat /home/rz41242/Projects/2017IsoSeq/genome/Araport/Araport11.201606.bed | awk -F"\t" '{split($11, b, ","); split($12, c, ",");d=""; for (i = 1; i < $10; i++){print $4"\t"$1"_"c[i]+$2+b[i]+1"_"c[i+1]+$2"_"$6}}'  > /mnt/shared/scratch/rz41242/2017Isoseq/sam/SplicedJunctions/SJ_araport

cd /mnt/shared/scratch/rz41242/2017Isoseq/sam/SplicedJunctions

###136,446 SJs in Araport11
cat SJ_araport | cut -f2 | sort | uniq > SJ_araport_sorted

###181,334 SJs in the merged50 and RTD2
#cat SJ_merged50_sorted SJ_RTD2_sorted | sort | uniq > SJ_merged50_RTD2_sorted

cat SJ_merged50_atRTD2 | cut -f2 | sort | uniq > SJ_merged50_RTD2_sorted


###shared SJs: 134,212, SJs unique to Araport: 2,234 (1.64% of all Araport SJs) and SJs unique to Iso-seq: 47,122
comm -12 SJ_merged50_RTD2_sorted SJ_araport_sorted | wc -l

comm -23 SJ_merged50_RTD2_sorted SJ_araport_sorted > SJ_merged50_RTD2_unique
comm -13 SJ_merged50_RTD2_sorted SJ_araport_sorted > SJ_araport_unique


###get the transcript contails novel SJs in Araport
####1,999 transcripts in Araport to add
cat SJ_araport |  awk 'BEGIN{while(getline<"SJ_araport_unique"){a[$1]="True"}}{if(a[$2]=="True"){print}}'| cut -f1 | sort | uniq > AraportTranscripts2add

####1,999 transcripts in Araport to add
cat /home/rz41242/Projects/2017IsoSeq/genome/Araport/Araport11.201606.bed | awk -F"\t" 'BEGIN{while(getline<"AraportTranscripts2add"){a[$1]=1}}{split($4, b, ";"); if(a[b[1]]==1){print}}'| awk '{split($4,a, ".");$4=a[1]";"$4; $5=40; $9="255,100,0"; $11=substr($11, 1, length($11)-1); $12=substr($12, 1, length($12)-1); print $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7"\t"$8"\t"$9"\t"$10"\t"$11"\t"$12}' >  Araport_Transcript2include.bed

cp Araport_Transcript2include.bed /mnt/shared/scratch/rz41242/2017Isoseq/sam/LDE_30_30_HD/FinalComparison

####identify novel loci in Araport11
cd /mnt/shared/scratch/rz41242/2017Isoseq/sam/LDE_30_30_HD/FinalComparison

conda activate isoseq3

####intersect with features on both strands
bedtools intersect -a merged50_atRTD2.bed -b /home/rz41242/Projects/2017IsoSeq/genome/Araport11_2016_gene.gff -wao > IsoseqAtRTD2_Araport11_Intersect_bothStrands

conda deactivate

####the output of the intersections between Iso-seq and Araport
###1. geneName_Isoseq; 2. transcriptID_Isoseq; 3. strand Isoseq; 4. Isoseq tx start coordinate; 5. Isoseq tx end coordinate;
###6. isoseq tx number of exons; 7. percentage of overlap with Araport gene (overlap/gene length); 
###8. Araport gene id; 9. Araport strand; 10. gene start coordindate; 11. gene end coordinate; 
###12. overlap percentage (overlap/gene length); 13. overlap length

cat IsoseqAtRTD2_Araport11_Intersect_bothStrands | cut -f4,6,7,8,10,16,17,19,21,22 | awk -F"\t" '{split($9,a,";");split($1, b, ";");print b[1]"\t"b[2]"\t"$2"\t"$3"\t"$4"\t"$5"\t"$10/($4-$3+1)"\t"a[1]"\t"$8"\t"$6"\t"$7"\t"$10/($7-$6+1)"\t"$10}'> IsoseqatRTD2_Araport11_gene_annotation_bothStrands

#######take the gene doesn't overlap with atIso+atRTD2 on the same strand (38,194-28,598=9,596 genes)
###28,598 overlapped genes
cat IsoseqatRTD2_Araport11_gene_annotation_bothStrands | awk '$3==$9{split($8,a,"=");print a[2]}'| sort | uniq > AraportOverlappedGenes


####add 9,767 transcripts
cat /home/rz41242/Projects/2017IsoSeq/genome/Araport/Araport11.201606.bed | awk -F"\t" 'BEGIN{while(getline<"AraportOverlappedGenes"){a[$1]=1}}{split($4, b, "."); if(a[b[1]]!=1){print}}' | awk '{split($4,a, ".");$4=a[1]";"$4; $5=40; $9="255,100,0"; $11=substr($11, 1, length($11)-1); $12=substr($12, 1, length($12)-1); print $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7"\t"$8"\t"$9"\t"$10"\t"$11"\t"$12}' >  AraportUnique.bed


###merge atIso+atRTD2 and Araport
###generate filelist for TAMA merge


###araport (11,766)
cat Araport_Transcript2include.bed AraportUnique.bed > Araport_Transcript2include2.bed


####merging atIso, atRTD2 and Araport
rm filelist.txt filelist3.txt

ls merged50.bed AtRTD2_19April2016_Transcript2include.bed Araport_Transcript2include.bed AraportUnique.bed | sort -r | awk '{split($1,a,".");if(NR==1){print $1"\tcapped\t1,1,1\t"a[1]}else{print $1"\tno_cap\t2,1,2\t"a[1]}}'>>filelist.txt

cat filelist.txt | awk '{$1="/mnt/shared/scratch/rz41242/2017Isoseq/sam/LDE_30_30_HD/FinalComparison/"$1;print $1"\t"$2"\t"$3"\t"$4}'> filelist3.txt

####merge transcripts allowing 50nt differences at TSS/TES
nohup python /home/rz41242/software/TAMA/tama/tama_merge.py -f filelist3.txt -p merged50_atRTD2_Araport -m 0 -a 50 -z 50 -d merge_dup &

##38,198 genes, 167,969 transcripts

cut -f4 merged50_atRTD2_Araport.bed | awk '{split($1, a, ";");print a[1]}'| sort | uniq | wc -l
cut -f4 merged50_atRTD2_Araport.bed | awk '{split($1, a, ";");print a[2]}'| sort | uniq | wc -l

####generate the origins of each transcript

less merged50_atRTD2_Araport_trans_report.txt| cut -f1,3 | sed 's/merged50/Isoseq/g' | sed 's/AtRTD2_19April2016_Transcript2include/atRTD2/g' | sed 's/AraportUnique/Araport/g' | sed 's/Araport_Transcript2include/Araport/g' | sed 's/Araport,Araport/Araport/g' | > Tx_origin 



######Analysis of gene coverage

###24,286 genes covered by Iso-seq
less Tx_origin | grep Isoseq | cut -f1 | cut -f1 -d"."| sort | uniq | wc -l

###13,463 genes covered by atRTD2
less Tx_origin | grep atRTD2 | grep -v Araport | cut -f1 | cut -f1 -d"."| sort | uniq | wc -l

####10,447 genes covered by Araport
less Tx_origin | grep Araport | grep -v atRTD2 | cut -f1 | cut -f1 -d"."| sort | uniq | wc -l

####11 genes covered by Araport and atRTD2
less Tx_origin | grep Araport | grep atRTD2 | cut -f1 | cut -f1 -d"."| sort | uniq | wc -l

####generate SJs
cat merged50_atRTD2_Araport_merge.txt | awk -F"\t" '{split($4, a, ";"); split($11, b, ","); split($12, c, ",");d=""; for (i = 1; i < $10; i++){print a[1]"\t"$1"_"c[i]+$7+b[i]+1"_"c[i+1]+$7"_"$6}}'  > /mnt/shared/scratch/rz41242/2017Isoseq/sam/SplicedJunctions/SJ_merged50_atRTD2_Araport

#####183,568 SJs
less SJ_merged50_atRTD2_Araport | cut -f2 | sort | uniq | wc -l 


##################################################
####Tx analysis 
#######annotations using Araport

conda activate isoseq3

####intersect with features on both strands
##bedtools intersect -a merged50_atRTD2_Araport.bed -b /home/rz41242/Projects/2017IsoSeq/genome/Araport11_2016_gene.gff -wao > IsoseqAtRTD2Araport_Araport11_Intersect_bothStrands

###August 4th, 2020
bedtools intersect -a merged50_atRTD2_Araport.bed -b Araport11.201606_formatted.bed -wao > IsoseqAtRTD2Araport_Araport11_Intersect_bothStrands

conda deactivate


####1. take field gene;transcript(f4), strand (f6), tx start and end (f7,8), number of exon (f10); matching tx start and end (f14,15), matching strand (f18), matching gene (f16), overlaps(f22)
cat IsoseqAtRTD2Araport_Araport11_Intersect_bothStrands | cut -f4,6,7,8,10,14,15,18,16,25 | awk -F"\t" '{split($9,a,";");split($1, b, ";");print b[1]"\t"b[2]"\t"$2"\t"$3"\t"$4"\t"$5"\t"$10/($4-$3+1)"\t"a[1]"\t"$8"\t"$6"\t"$7"\t"$10/($7-$6+1)"\t"$10}'> IsoseqatRTD2Araport_Araport11_gene_annotation_bothStrands


####on the same strand, some transcript covers multiple gene models (true chimeric transcripts 3,127)
 cat IsoseqatRTD2Araport_Araport11_gene_annotation_bothStrands | awk '$3==$8&&$12>0.3{split($9,a,";");print $2"\t"a[1]}'| sort | uniq | cut -f1 | uniq -c | sort -nr | awk '$1>1{print}'| wc -l
 
 ####annotation: 1) on the same strand $3==$8; 2) the overlap between two txs should be more than 30% of either txs.
 cat IsoseqatRTD2Araport_Araport11_gene_annotation_bothStrands | awk '$3==$8&&($12>0.3||$7>0.3){split($9,a,";");print $2"\t"a[1]}'| sort | uniq | awk 'BEGIN{Gname1="Gname1";Gname2="Gname2"}{if(Gname1==$1){Gname2=Gname2"-"$2}else{print Gname1"\t"Gname2;Gname1=$1;Gname2=$2}}END{print Gname1"\t"Gname2}'> Tx_annotation_atIso3
 
 ##############identify run through tx (cover Araport gene >50%)
#cat IsoseqatRTD2Araport_Araport11_gene_annotation_bothStrands | awk '$3==$8&&$12>0.5{split($9,a,";");print $2"\t"a[1]}'| sort | uniq | awk 'BEGIN{Gname1="Gname1";Gname2="Gname2"}{if(Gname1==$1){Gname2=Gname2"-"$2}else{print Gname1"\t"Gname2; Gname1=$1;Gname2=$2}}END{print Gname1"\t"Gname2}'> Tx_annotation_atIso3> Tx_annotation_atIso3_t05 

####3,796 run through tx from 1578 genes
 less Tx_annotation_atIso3 | grep "-" | wc -l
 #### 1,124
 less Tx_annotation_atIso3 | grep "-" | cut -f1 | cut -d"." -f1 | sort | uniq | wc -l

###put in annotations and orgins for transcripts and genes
###Tx_origin
##Tx_annotation_atIso3

####generate transcript ID according to the overlaps with Araport
cat Tx_annotation_atIso3 | sed '1d' | sort --version-sort -k2 | awk 'BEGIN{n=1; gname="NA"}{if(gname==$2){n=n+1;print $1"\t"$2"\t"$2"."n; }else{gname=$2;n=1;print $1"\t"$2"\t"$2"."n;}}END{print $1"\t"$2"\t"$2"."n;}'> Tx_annotation_atIso3_tx

cat merged50_atRTD2_Araport.bed | awk -F"\t" 'BEGIN{while(getline<"Tx_annotation_atIso3_tx"){a[$1]=$2;tx[$1]=$3};while(getline<"Tx_origin"){Txo[$1]=$2}}{split($4, b, ";");; if(a[b[2]]){$4=a[b[2]]";"tx[b[2]]";"Txo[b[2]]}else{$4=$4";"Txo[b[2]]}; print $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7"\t"$8"\t"$9"\t"$10"\t"$11"\t"$12}'> atRTD3.bed



 

####SJ analysis using SUPPA




####oct 26, 2020


suppa.py generateEvents -i atIso_07082020.gtf -o atIso_07082020  -f ioe -e {'SE','SS','MX','RI','FL'} -b S

### total events 94,548
cat atIso_07082020*_strict.ioe | wc -l
###A3: 26135 (%); A5: 12339 (27.16%); AF: 2613; AL: 145; MX: 221; RI: 47498 (%); SE: 5597; 
for i in `ls atIso_07082020*_strict.ioe`
do
echo $i
cat $i | wc -l
done

####nov 4, apply strict boundary
suppa.py generateEvents -i atRTD3_07082020.gtf -o atRTD3_07082020 -f ioe -e {'SE','SS','MX','RI','FL'} -b S
##
### total events 117,793
#cat atRTD3_07082020*_variable_10.ioe | wc -l
cat atRTD3_07082020*_strict.ioe | wc -l

###A3: 33474 (28.4%); A5: 17074 (14.49%); AF: 6602; AL: 599; MX: 316; RI: 52246 (44.35%); SE: 7482; 
#for i in `ls atRTD3_07082020*_variable_10.ioe`
for i in `ls atRTD3_07082020*__strict.ioe`
do
echo $i
cat $i | wc -l
done


#####
suppa.py generateEvents -i AtRTD2_19April2016.gtf -o atRTD2 -f ioe -e {'SE','SS','MX','RI','FL'} -b S

### total events 43,960
cat atRTD2*strict.ioe | wc -l
###A3: 13630 (%); A5: 7785 (%); AF: 2890; AL: 283; MX: 81; RI: 16447 (%); SE: 2844; 
for i in `ls atRTD2*strict.ioe`
do
echo $i
cat $i | wc -l
done

####Araport
scp Araport11_GFF3_genes_transposons.201606.gtf.gz rzhang@gruffalo.cropdiversity.ac.uk:/mnt/shared/scratch/rzhang/private/2017Isoseq/sam/LDE_30_30_HD/FinalComparison

#####
suppa.py generateEvents -i Araport11_GFF3_genes_transposons.201606.gtf -o Araport -f ioe -e {'SE','SS','MX','RI','FL'} -b S

### total events 15,488
cat Araport*strict.ioe | wc -l
###A3: 4209 (%); A5: 3160 (%); AF: 936; AL: 107; MX: 31; RI: 5993 (%); SE: 1052; 
for i in `ls Araport*strict.ioe`
do
echo $i
cat $i | wc -l
done
